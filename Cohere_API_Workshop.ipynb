{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saad-a-li/Cohere/blob/main/Cohere_API_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cohere API Workshop**\n",
        "University of Waterloo Data Science Club | June 2023"
      ],
      "metadata": {
        "id": "3kBmdph-9VvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook has been created to compliment the LLM API slide deck. In this notebook we explore the different Cohere API endpoints as well as LangChain.\n",
        "\n",
        "**Before running the cells:**\n",
        "1. Create a copy of this notebook by navigating to: File > Save a copy in Drive. This allows you to edit the notebook.\n",
        "\n",
        "2. The first step is to create a Cohere account [here](https://dashboard.cohere.ai/welcome/register?__hstc=14363112.b9ea3a4df23480959007724c0be23db2.1684965394606.1685218260676.1686410973933.3&__hssc=14363112.1.1686410973933&__hsfp=2642313323).\n",
        "\n",
        "3. Once you have logged in to the Cohere platform, on the left pannel navigate to: SETTINGS > API Keys. Then scroll down to Trial keys and press the copy icon next to your default key.\n",
        "\n",
        "4. Paste your API key in quotations to replace the 'api_key' string two cells down. Now you are ready to run the code!\n",
        "\n",
        "Note that there is also a way to use some of the functionality of Cohere's API without needing to use any code at all. To explore this press the PLAYGROUND button on the top right hand corner once you are logged in. As of right now, you can use the generate, classify, embed, and summarize endpoints. Once you have found a setup you like, you can press the View code button below the PLAYGROUND button and this will automatically create the code you need to get the job done."
      ],
      "metadata": {
        "id": "FyzGMw-z9Viz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Setup\n",
        "There is a python library to interface with the Cohere API. It can be easily installed using PIP. Then we can import the libraries we need and authenticate ourselves using the API key we generated in the steps above."
      ],
      "metadata": {
        "id": "I0Z8TT4571mF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LfyedfQ9QOq"
      },
      "outputs": [],
      "source": [
        "! pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cohere\n",
        "from cohere.responses.classify import Example\n",
        "\n",
        "api_key = 'api_key'  # Add your API key here instead of api_key\n",
        "co = cohere.Client(api_key)"
      ],
      "metadata": {
        "id": "ip7Zk3UAgLkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate\n",
        "Generates a text completion based on prompt. This is the most basic endpoint but can be used for all sorts of interesting and creative purposes.\n",
        "\n",
        "The only required argument to get started with it is just the prompt as shown below."
      ],
      "metadata": {
        "id": "0HazD_qvscnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = co.generate(prompt='Generate a list of reasons why learning data science is good')\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gem44ARjgLaA",
        "outputId": "824ffcef-301e-480a-d86a-8465690465d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cohere.Generation {\n",
            "\tid: 55261d17-648d-4312-a52f-897c8e91c597\n",
            "\tprompt: Generate a list of reasons why learning data science is good\n",
            "\ttext: \n",
            "1. Learning data science will help you understand how to use data to make decisions\n",
            "2.\n",
            "\tlikelihood: None\n",
            "\ttoken_likelihoods: None\n",
            "}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now there are a lot of additional peices of information here that may make it hard to clearly see what the completion was so we can just print the text response part as shown in the code block below."
      ],
      "metadata": {
        "id": "DSCLDos_8fSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.generations[0].text) # To just see the text only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suh_xOWwgLXn",
        "outputId": "149fdcd0-558a-4c96-896a-debfa16e3c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Learning data science will help you understand how to use data to make decisions\n",
            "2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But this is sort of unfortunate, because the default completion is so short and cut off mid-scentence. Sometimes these outputs will cut off mid-scentence becasue of the max_tokens number being reached, the default value is 20 but this is something we can edit. Below I change this to 200 for a longer output."
      ],
      "metadata": {
        "id": "rm8PjVQj8nma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = co.generate(\n",
        "  prompt='Generate a list of reasons why learning data science is good',\n",
        "  max_tokens=200)\n",
        "print(response.generations[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PTC4lYI8q_G",
        "outputId": "66d1df80-b53d-43e0-c163-725319b0f570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "- Data science is a high-paying field\n",
            "- The skills learned in data science are transferable to other fields\n",
            "- The demand for data scientists is high\n",
            "- The work is rewarding\n",
            "- The skills learned in data science are useful in a variety of industries\n",
            "- The field is constantly changing, so there is always something new to learn\n",
            "- The field is interdisciplinary, so you can apply your skills in a variety of ways\n",
            "- The field is international, so you can work anywhere in the world\n",
            "- The field is in demand, so there are many job opportunities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are interested in learning about how you can change other default parameters, use the [API reference on the Cohere documentation website](https://docs.cohere.com/reference/generate).\n",
        "\n",
        "One of the next-most influencial parameters is temperature. Below is a function that calls the generate endpoint with specific default parameters changed like the model used as well as the number of outputs generated."
      ],
      "metadata": {
        "id": "vKFkd9Jb8qkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to call the endpoint\n",
        "def generate_text(prompt, temperature, num_gens=3):\n",
        "  response = co.generate(\n",
        "    model='command-nightly',\n",
        "    prompt=prompt,\n",
        "    max_tokens=100,\n",
        "    temperature=temperature,\n",
        "    num_generations = num_gens,\n",
        "    return_likelihoods='GENERATION')\n",
        "  return response"
      ],
      "metadata": {
        "id": "P2SG9s-ZgLUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can set a range of temperatures to explore and a prompt to use. As you can see from the outputs of the cell below, as temperature is increased the outputs become more creative and different from one another."
      ],
      "metadata": {
        "id": "2zhHxBSf8ynh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt\n",
        "prompt='Generate a concise but catchy tagline for the University of Waterloo Data Science Club.'\n",
        "\n",
        "# Define the range of temperature values and num_generations\n",
        "temperatures = [x / 10.0 for x in range(0, 60, 10)]\n",
        "\n",
        "# Iterate generation over the range of temperature values\n",
        "for temperature in temperatures:\n",
        "  response = generate_text(prompt, temperature)\n",
        "  print(\"-\"*10)\n",
        "  print(f'Temperature: {temperature}')\n",
        "  print(\"-\"*10)\n",
        "  for i in range(3):\n",
        "    text = response.generations[i].text\n",
        "    likelihood = response.generations[i].likelihood\n",
        "    print(f'Generation #{i+1}')\n",
        "    print(f'Text: {text}\\n')\n",
        "    print(f'Likelihood: {likelihood}\\n')\n",
        "\n",
        "  # Pause due to rate limitting\n",
        "  time.sleep(60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FdRDU6484bY",
        "outputId": "f47871d5-660f-4476-d5c0-d849607199b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "Temperature: 0.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "\n",
            "Data Science Club | University of Waterloo\n",
            "\n",
            "Likelihood: -0.3078624\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "\n",
            "Data Science Club | University of Waterloo\n",
            "\n",
            "Likelihood: -0.30933592\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "\n",
            "Data Science Club | University of Waterloo\n",
            "\n",
            "Likelihood: -0.3081709\n",
            "\n",
            "----------\n",
            "Temperature: 1.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "\n",
            "Data Science. Knowledge Discovery. Empowering tomorrow.\n",
            "\n",
            "Likelihood: -1.8021718\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "\n",
            "Data Science Club | University of Waterloo\n",
            "\n",
            "Likelihood: -0.30933592\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "\n",
            "Data Science Club | Data Science for All\n",
            "\n",
            "Likelihood: -0.69838613\n",
            "\n",
            "----------\n",
            "Temperature: 2.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "\n",
            "Data Science Club | University of Waterloo\n",
            "\n",
            "Likelihood: -0.3078624\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "\n",
            "The University of Waterloo Data Science Club: Building a community of data science experts.\n",
            "\n",
            "Likelihood: -0.5085161\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "\n",
            "Data Science. intersects. Everything.\n",
            "\n",
            "Likelihood: -1.19391\n",
            "\n",
            "----------\n",
            "Temperature: 3.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "\n",
            "Data Science. Globally. Club.\n",
            "\n",
            "Likelihood: -1.5073417\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "\n",
            "The University of Waterloo Data Science Club:  Promoting the Data Sciences through Talks, Workshops, and More!\n",
            "\n",
            "Likelihood: -0.94232565\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "\n",
            "Data Science. Artificial Intelligence. Those who crunch, those who flinch.\n",
            "\n",
            "Likelihood: -1.7110174\n",
            "\n",
            "----------\n",
            "Temperature: 4.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "\n",
            "Data Science Club | UW Data Science Club\n",
            "\n",
            "Likelihood: -0.64323586\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "\n",
            "Data Science Club | Where Data Science happens.\n",
            "\n",
            "Likelihood: -0.7461004\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "\n",
            "Data Science Club | One university, multiple perspectives.\n",
            "\n",
            "Likelihood: -1.1741227\n",
            "\n",
            "----------\n",
            "Temperature: 5.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "\n",
            "The University of Waterloo Data Science Club: Data science for everyone!\n",
            "\n",
            "Likelihood: -0.44492796\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "\n",
            "Data Science Club | Water Cooler Conversations for Data Scientists\n",
            "\n",
            "Likelihood: -1.0366656\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "\n",
            "The University of Waterloo Data Science Club: Building a Data-Driven Future\n",
            "\n",
            "Likelihood: -0.6229089\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the examples above, I've used this endpoint in a really similar and basic way. However, at some point you may run into situations where you need more specific kinds of outputs to complete more challenging tasks, this is where prompt engineering comes into play. An example of prompt engineering is shown below where the background is taken from an [article](https://www.therecord.com/news/waterloo-region/2015/04/21/wild-turkey-smashes-uw-window-after-canada-geese-attack.html) called \"Wild turkey smashes UW window after Canada geese attack\" from The Record."
      ],
      "metadata": {
        "id": "vDY2B9wJ868h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"Background on the recent Waterloo geese attack:\\n WATERLOO — The Spawn of Satan, as deviously dubbed by his detractors,\\\n",
        " was missing from the big bird's usual lunch-hour perch as rain began to pour on Tuesday. Neither the ghoulish goose, nor his less-notorious \\\n",
        " posse, peered over the fat lip of the lower roof beside the University of Waterloo's Humanities Theatre. Maybe the Canada geese were nursing \\\n",
        " a gaggle of guilty consciences. It had been a wild 24 hours in the Hagey Hall heart of a goose-friendly campus — with its creek, little lakes \\\n",
        " and marshlands — that pushes stuffed geese and I-survived-nesting-season T-shirts at the school swag shop. It started with a few bangs above the \\\n",
        " mostly enclosed courtyard. The wild turkey, who had inexplicably taken up residence in the area late last week appeared to have been harassed and \\\n",
        " hemmed into the square by territorial goose tormentors, was trying to fly to freedom, school officials confirm. The bullied butterball made it \\\n",
        " three stories high before crashing into an empty philosophy seminar room.\"\n",
        "\n",
        "answer_start = \"Poem inspired from the text above: Oh the waterloo geese,\"\n",
        "\n",
        "response = co.generate(\n",
        "  prompt=context+answer_start,\n",
        "  max_tokens=200)\n",
        "print(response.generations[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWOjMLl-89En",
        "outputId": "c36cd1f5-c51e-4414-ca5e-d3991648e60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Oh the waterloo geese,\n",
            "A wild turkey in their sights,\n",
            "They chased him from the yard,\n",
            "And he tried to fly away,\n",
            "But the turkey wasn't quick enough,\n",
            "And he crashed into a room,\n",
            "Where he lay in a heap,\n",
            "Until the end of his days.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify\n",
        "The second endpoint we will use is able to classify sections of text into labels that you create. In order for this to work you need to give it some examples.\n",
        "\n",
        "Below, I create a few example workshop reviews for our UWDSC workshops and note if they are good or bad. Then I have a list of other reviews that I want to know if they are good or bad without having to read them all so I input them to the classify endpoint."
      ],
      "metadata": {
        "id": "ZXAHc2UXsfiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_lst = [Example(\"the uwdsc is the worst\", \"bad\"), Example(\"the uwdsc is the best\", \"good\"), Example(\"a waste of time\", \"bad\"), Example(\"incredibly useful\", \"good\")] # can also add examples from a file\n",
        "input_lst = [\"i hated the data science club workshops\", \"the workshop sucked\", \"the workshop was helpful\", \"the data science club workshops are the best thing ever\", \"it was okay\", \"would go again\"]\n",
        "\n",
        "response = co.classify(\n",
        "  model='embed-english-v2.0',\n",
        "  inputs=input_lst,\n",
        "  examples=example_lst)"
      ],
      "metadata": {
        "id": "FBuk5ej3hZSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for r, input in zip(response.classifications, input_lst):\n",
        "  print('################')\n",
        "  print(input)\n",
        "  print(r.prediction, 'with confidence', round(r.confidence,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp8zwsDahZQf",
        "outputId": "3b4e5df3-e940-469f-acbd-357018048692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################\n",
            "i hated the data science club workshops\n",
            "bad with confidence 0.97\n",
            "################\n",
            "the workshop sucked\n",
            "bad with confidence 0.96\n",
            "################\n",
            "the workshop was helpful\n",
            "good with confidence 0.993\n",
            "################\n",
            "the data science club workshops are the best thing ever\n",
            "good with confidence 0.996\n",
            "################\n",
            "it was okay\n",
            "bad with confidence 0.897\n",
            "################\n",
            "would go again\n",
            "good with confidence 0.903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarize\n",
        "Summarize a chunk of text. This example shows a really short summary but you can make it longer by changing lenght from 'short' to 'medium' or 'long'.\n",
        "\n",
        "Text in the example is copied from: https://www.britannica.com/biography/Taylor-Swift"
      ],
      "metadata": {
        "id": "6fBNhpPKuNX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = co.summarize(\n",
        "  text='Early life\\nSwift showed an interest in music at an early age, and she progressed quickly from roles in children’s theatre to her first appearance before a crowd of thousands. She was age 11 when she sang “The Star-Spangled Banner” before a Philadelphia 76ers basketball game, and the following year she picked up the guitar and began to write songs. Taking her inspiration from country music artists such as Shania Twain and the Dixie Chicks, Swift crafted original material that reflected her experiences of tween alienation. When she was 13, Swift’s parents sold their farm in Pennsylvania to move to Hendersonville, Tennessee, so that she could devote more of her time to courting country labels in nearby Nashville.\\n\\n(Left) Luis Fonsi and Daddy Yankee (Ramon Luis Ayala Rodriguez) perform during the 2017 Billboard Latin Music Awards and Show at the Bank United Center, University of Miami, Miami, Florida on April 27, 2017. (music)\\nBritannica Quiz\\n2010s Music Quiz\\nA development deal with RCA Records allowed Swift to make the acquaintance of recording-industry veterans, and in 2004, at age 14, she signed with Sony/ATV as a songwriter. At venues in the Nashville area, she performed many of the songs she had written, and it was at one such performance that she was noticed by record executive Scott Borchetta. Borchetta signed Swift to his fledgling Big Machine label, and her first single, “Tim McGraw” (inspired by and prominently referencing a song by Swift’s favourite country artist), was released in the summer of 2006.\\n\\nDebut album and Fearless\\nTaylor Swift\\nTaylor Swift\\nThe song was an immediate success, spending eight months on the Billboard country singles chart. Now age 16, Swift followed with a self-titled debut album, and she went on tour, opening for Rascal Flatts. Taylor Swift was certified platinum in 2007, having sold more than one million copies in the United States, and Swift continued a rigorous touring schedule, opening for artists such as George Strait, Kenny Chesney, Tim McGraw, and Faith Hill. That November Swift received the Horizon Award for best new artist from the Country Music Association (CMA), capping the year in which she emerged as country music’s most-visible young star.\\n\\nOn Swift’s second album, Fearless (2008), she demonstrated a refined pop sensibility, managing to court the mainstream pop audience without losing sight of her country roots. With sales of more than half a million copies in its first week, Fearless opened at number one on the Billboard 200 chart. It ultimately spent more time atop that chart than any other album released that decade. Singles such as “You Belong with Me” and “Love Story” were popular in the digital market as well, the latter accounting for more than four million paid downloads.\\n\\nKanye West incident at the VMAs, Red, and 1989\\nTaylor Swift\\nTaylor Swift\\nIn 2009 Swift embarked on her first tour as a headliner, playing to sold-out venues across North America. That year also saw Swift dominate the industry award circuit. Fearless was recognized as album of the year by the Academy of Country Music in April, and she topped the best female video category for “You Belong with Me” at the MTV Video Music Awards (VMAs) in September. During her VMA acceptance speech, Swift was interrupted by rapper Kanye West, who protested that the award should have gone to Beyoncé for what he called “one of the best videos of all time.” Later in the program, when Beyoncé was accepting the award for video of the year, she invited Swift onstage to conclude her speech, a move that drew a standing ovation for both performers. At the CMA Awards that November, Swift won all four categories in which she was nominated. Her recognition as CMA entertainer of the year made her the youngest-ever winner of that award, as well as the first female solo artist to win since 1999. She began 2010 with an impressive showing at the Grammy Awards, where she collected four honours, including best country song, best country album, and the top prize of album of the year.\\n\\n\\n\\nGet a Britannica Premium subscription and gain access to exclusive content.\\nLater that year Swift made her feature-film debut in the romantic comedy Valentine’s Day and was named the new spokesperson for CoverGirl cosmetics. Although Swift avoided discussing her personal life in interviews, she was surprisingly frank in her music. Her third album, Speak Now (2010), was littered with allusions to romantic relationships with John Mayer, Joe Jonas of the Jonas Brothers, and Twilight series actor Taylor Lautner. Swift reclaimed the CMA entertainer of the year award in 2011, and the following year she won Grammys for best country solo performance and best country song for “Mean,” a single from Speak Now.\\n\\nTaylor Swift\\nTaylor Swift\\nTaylor Swift\\nTaylor Swift\\nSwift continued her acting career with a voice role in the animated Dr. Seuss’ The Lorax (2012) before releasing her next collection of songs, Red (2012). While she remained focused on the vagaries of young love, her songwriting reflected a deepened perspective on the subject, and much of the album embraced a bold pop-rock sound. In its first week on sale in the United States, Red sold 1.2 million copies—the highest one-week total in 10 years. In addition, its lead single, the gleeful “We Are Never Ever Getting Back Together,” gave Swift her first number-one hit on the Billboard pop singles chart.\\n\\nIn 2014 Swift released 1989, an album titled after the year of her birth and reportedly inspired by the music of that era. Although Swift had already been steadily moving away from the traditional country signifiers that marked her early work—“I Knew You Were Trouble,” the second single from Red, even flirted with electronic dance music—she called 1989 her first “official pop album.” On the strength of the upbeat “Shake It Off,” the album proved to be another blockbuster for Swift, with its first-week sales surpassing those of Red. It went on to sell more than five million copies in the United States and earned Swift her second Grammy for album of the year. In 2014 Swift also appeared in a supporting role in The Giver, a film adaptation of Lois Lowry’s dystopian novel for young readers.\\n\\nMichael Ray\\nReputation, Lover, Folklore, Evermore, Midnights, and controversies\\nTaylor Swift\\nTaylor Swift\\nIn 2016 Swift’s feud with Kanye West resumed after he released the single “Famous.” The song included a lyric in which Swift was referred to as a “bitch,” and she alleged that it was misogynistic. The public spat escalated after West’s wife, Kim Kardashian, released a recording of a phone call in which Swift gave her approval for the line, though West made no mention of calling her a bitch. Swift’s controversies continued as she took part in a widely publicized civil trial in August 2017, after former radio host David Mueller sued the singer, her mother, and a promoter, claiming that Swift had falsely accused him of sexually groping her in 2013 during the taking of a photograph and thus destroyed his career. She countersued, maintaining that the assault had taken place. At the trial, Swift was removed from Mueller’s suit and the other two defendants were found not liable as the jury found in favour of Swift’s countersuit. Shortly thereafter Swift released the hit song “Look What You Made Me Do,” and her album Reputation became the top-selling American LP of 2017.\\n\\nIn 2018 Swift left Big Machine and signed with Republic Records and Universal Music Group. The following year her former label, which owned the master recordings of her six albums, was sold to Scooter Braun, a talent manager whose clients had included Kanye West. Swift publicly spoke out against the deal, claiming that Borchetta had rejected her attempts to acquire the master tapes and that Braun had bullied her over the years. She subsequently tried to negotiate a deal with Braun, but he sold her back catalog to a private investment firm in 2020. Against this backdrop, Swift began rerecording her early material in an effort to gain control of it—the hope being that her remade songs and not the originals would be sought out for licensing deals—and in 2021 Fearless (Taylor’s Version) and Red (Taylor’s Version) appeared. They were remakes of earlier albums with several previously unreleased tracks.\\n\\nTaylor Swift\\nTaylor Swift\\nIn 2019 Swift released her seventh album, Lover, which she described as “a love letter to love itself.” That year she also appeared in the musical Cats, a film adaptation of Andrew Lloyd Webber’s hugely successful stage production. Miss Americana (2020) is a documentary about her life and career. With little advance notice, she released Folklore in 2020. A departure from her previous pop-inspired work, Swift’s eighth studio album drew praise for its introspection and restraint, and it won the Grammy for album of the year. The “sister record,” Evermore, appeared later in 2020. Swift adopted a synth-pop sound for the candid Midnights (2022), which she described as “the story of 13 sleepless nights scattered throughout my life.”',\n",
        "  length='short',\n",
        "  format='auto',\n",
        "  model='summarize-xlarge',\n",
        "  additional_command='',\n",
        "  temperature=0.1,\n",
        ")\n",
        "\n",
        "print('Summary:', response.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la2qYQbpuNx9",
        "outputId": "67914764-e7bf-4788-a319-c24a992bb798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Taylor Swift is a popular American singer-songwriter who has won numerous awards for her work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rerank\n",
        "Returns list of most relevant search results from chunks of text.\n"
      ],
      "metadata": {
        "id": "BmYKCQDD9MOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['Carson City is the capital city of the American state of Nevada.',\n",
        "'The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is Saipan.',\n",
        "'Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district.',\n",
        "'Capital punishment (the death penalty) has existed in the United States since beforethe United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.']\n",
        "\n",
        "response = co.rerank(\n",
        "  model = 'rerank-english-v2.0',\n",
        "  query = 'What is the capital of the United States?',\n",
        "  documents = docs,\n",
        "  top_n = 3,\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VQvERsK9QGl",
        "outputId": "e8d6107e-8207-472f-fb80-73041904db17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RerankResult<document['text']: Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district., index: 2, relevance_score: 0.98005307>, RerankResult<document['text']: Capital punishment (the death penalty) has existed in the United States since beforethe United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states., index: 3, relevance_score: 0.27904198>, RerankResult<document['text']: Carson City is the capital city of the American state of Nevada., index: 0, relevance_score: 0.10194652>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect Language\n",
        "This endpoint returns the langauges of the provided text."
      ],
      "metadata": {
        "id": "V5bjgSg79R2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_lst = [\"Hello world\", \"'Здравствуй, Мир'\", \"Hallo Welt\", \"Hej Verden\", \"Hei maailma\", \"Hej världen\"]\n",
        "\n",
        "response = co.detect_language(\n",
        "  texts=text_lst\n",
        ")\n",
        "\n",
        "for language, text in zip(response.results, text_lst):\n",
        "  print(language.language_name, ':', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anFhyOzd9UAV",
        "outputId": "797e2aac-4554-47f7-d9a0-1d6c4da73ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English : Hello world\n",
            "Russian : 'Здравствуй, Мир'\n",
            "German : Hallo Welt\n",
            "Polish : Hej Verden\n",
            "Finnish : Hei maailma\n",
            "Swedish : Hej världen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free to play around with other languages, [here](https://mixable.blog/hello-world-in-74-natural-languages/) you can find \"Hello world!\" written in 74 natural languages."
      ],
      "metadata": {
        "id": "H-bBOv_B9Vdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain\n",
        "This is a framework to help you build applications powered by LLMs. It can work with a long list of LLMs including Cohere's models.\n",
        "\n",
        "You can read more about all the utilities [here](https://python.langchain.com/en/latest/index.html) and see all sorts of other examples. Two really neat examples not shown here are being able to query documents and using chains.\n",
        "\n",
        "Much of the code below was taken from this github [repo](https://github.com/sophiamyang/tutorials-LangChain/tree/main)."
      ],
      "metadata": {
        "id": "vLYH1XEu9Wp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain"
      ],
      "metadata": {
        "id": "gPa4HAOU9Yig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import langchain\n",
        "from langchain.llms import Cohere\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferWindowMemory, CombinedMemory, ConversationSummaryMemory\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "VsSjSb929bUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = api_key\n",
        "cohere = Cohere(model='command-xlarge')"
      ],
      "metadata": {
        "id": "Psu53anc9dHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic text generation\n",
        "text = \"How to be happy as a waterloo student in midterm season?\"\n",
        "print(cohere(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRh6HipD9emS",
        "outputId": "9d3931c6-e7bf-4a34-f440-5671712e3f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "As a Waterloo student in midterm season, you can try to be happy by managing your time effectively, getting enough sleep and exercise, and taking breaks when needed. You can also try to stay motivated by setting goals for yourself and rewarding yourself when you achieve them. Additionally, it can be helpful to surround yourself with supportive friends and family members who can help you feel less stressed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot\n",
        "conv_memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history_lines\",\n",
        "    input_key=\"input\",\n",
        "    k=1\n",
        ")\n",
        "\n",
        "summary_memory = ConversationSummaryMemory(llm=Cohere(), input_key=\"input\")\n",
        "\n",
        "memory = CombinedMemory(memories=[conv_memory, summary_memory])\n",
        "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
        "\n",
        "Summary of conversation:\n",
        "{history}\n",
        "Current conversation:\n",
        "{chat_history_lines}\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\", \"chat_history_lines\"], template=_DEFAULT_TEMPLATE\n",
        ")\n",
        "llm = Cohere(temperature=0)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    prompt=PROMPT\n",
        ")"
      ],
      "metadata": {
        "id": "iGC_eQA49gae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.run(\"Hey! What's up?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "88n8t1DV9hij",
        "outputId": "5c4d0c09-1e18-4727-ae54-1ea35f279e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Summary of conversation:\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hey! What's up?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nHey! I'm doing well, how about you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.run(\"I'm doing well too, but a bit bored. Do you have any fun ideas for side projects I could work on?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "wui48J-j9jOh",
        "outputId": "46934884-3faa-40e7-f4f4-ad613b2dd928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Summary of conversation:\n",
            "\n",
            "The human and AI greeted each other.\n",
            "Current conversation:\n",
            "Human: Hey! What's up?\n",
            "AI: \n",
            "Hey! I'm doing well, how about you?\n",
            "Human: I'm doing well too, but a bit bored. Do you have any fun ideas for side projects I could work on?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSure! There are a few things you could try. For one, you could try building a small game or app. This would give you something to work on and also be a fun project to show off to your friends. You could also try learning a new skill, like programming or design. This would be a great way to keep yourself busy and also learn something new.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thanks for following along with this tutorial, to learn more about LangChain specifically reference their [handbook](https://www.pinecone.io/learn/langchain-intro/). My personal recommendation is to check out the Building Custom Tools for LLM Agents chapter and see how they make it possible to give an LLM access to a simple calculator so that it can actually do math that makes sense.\n"
      ],
      "metadata": {
        "id": "_nm7CrdV9nLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the workshop session Luis sent a link to LangChain lab on the Cohere website that you can access [here](https://txt.cohere.com/search-cohere-langchain/), it walks you through how to build a multilingual semantic search application on top of Cohere's multilingual model."
      ],
      "metadata": {
        "id": "z6UssOV8AsJv"
      }
    }
  ]
}